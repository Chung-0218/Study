{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27a76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sclab\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.221\n",
      "[1,  4000] loss: 0.879\n",
      "[1,  6000] loss: 0.764\n",
      "[1,  8000] loss: 0.712\n",
      "[1, 10000] loss: 0.664\n",
      "[1, 12000] loss: 0.628\n",
      "[2,  2000] loss: 0.469\n",
      "[2,  4000] loss: 0.477\n",
      "[2,  6000] loss: 0.482\n",
      "[2,  8000] loss: 0.496\n",
      "[2, 10000] loss: 0.470\n",
      "[2, 12000] loss: 0.459\n",
      "[3,  2000] loss: 0.299\n",
      "[3,  4000] loss: 0.324\n",
      "[3,  6000] loss: 0.314\n",
      "[3,  8000] loss: 0.366\n",
      "[3, 10000] loss: 0.358\n",
      "[3, 12000] loss: 0.334\n",
      "[4,  2000] loss: 0.203\n",
      "[4,  4000] loss: 0.223\n",
      "[4,  6000] loss: 0.248\n",
      "[4,  8000] loss: 0.250\n",
      "[4, 10000] loss: 0.270\n",
      "[4, 12000] loss: 0.267\n",
      "[5,  2000] loss: 0.171\n",
      "[5,  4000] loss: 0.180\n",
      "[5,  6000] loss: 0.190\n",
      "[5,  8000] loss: 0.209\n",
      "[5, 10000] loss: 0.198\n",
      "[5, 12000] loss: 0.197\n",
      "[6,  2000] loss: 0.133\n",
      "[6,  4000] loss: 0.156\n",
      "[6,  6000] loss: 0.146\n",
      "[6,  8000] loss: 0.162\n",
      "[6, 10000] loss: 0.171\n",
      "[6, 12000] loss: 0.188\n",
      "[7,  2000] loss: 0.098\n",
      "[7,  4000] loss: 0.129\n",
      "[7,  6000] loss: 0.134\n",
      "[7,  8000] loss: 0.140\n",
      "[7, 10000] loss: 0.140\n",
      "[7, 12000] loss: 0.161\n",
      "[8,  2000] loss: 0.090\n",
      "[8,  4000] loss: 0.111\n",
      "[8,  6000] loss: 0.114\n",
      "[8,  8000] loss: 0.122\n",
      "[8, 10000] loss: 0.125\n",
      "[8, 12000] loss: 0.132\n",
      "[9,  2000] loss: 0.071\n",
      "[9,  4000] loss: 0.107\n",
      "[9,  6000] loss: 0.112\n",
      "[9,  8000] loss: 0.115\n",
      "[9, 10000] loss: 0.093\n",
      "[9, 12000] loss: 0.103\n",
      "[10,  2000] loss: 0.052\n",
      "[10,  4000] loss: 0.096\n",
      "[10,  6000] loss: 0.074\n",
      "[10,  8000] loss: 0.116\n",
      "[10, 10000] loss: 0.109\n",
      "[10, 12000] loss: 0.105\n",
      "[11,  2000] loss: 0.093\n",
      "[11,  4000] loss: 0.074\n",
      "[11,  6000] loss: 0.101\n",
      "[11,  8000] loss: 0.103\n",
      "[11, 10000] loss: 0.080\n",
      "[11, 12000] loss: 0.087\n",
      "[12,  2000] loss: 0.067\n",
      "[12,  4000] loss: 0.069\n",
      "[12,  6000] loss: 0.085\n",
      "[12,  8000] loss: 0.106\n",
      "[12, 10000] loss: 0.075\n",
      "[12, 12000] loss: 0.094\n",
      "[13,  2000] loss: 0.083\n",
      "[13,  4000] loss: 0.083\n",
      "[13,  6000] loss: 0.073\n",
      "[13,  8000] loss: 0.089\n",
      "[13, 10000] loss: 0.097\n",
      "[13, 12000] loss: 0.111\n",
      "[14,  2000] loss: 0.065\n",
      "[14,  4000] loss: 0.083\n",
      "[14,  6000] loss: 0.100\n",
      "[14,  8000] loss: 0.073\n",
      "[14, 10000] loss: 0.062\n",
      "[14, 12000] loss: 0.099\n",
      "[15,  2000] loss: 0.108\n",
      "[15,  4000] loss: 0.090\n",
      "[15,  6000] loss: 0.094\n",
      "[15,  8000] loss: 0.071\n",
      "[15, 10000] loss: 0.091\n",
      "[15, 12000] loss: 0.104\n",
      "[16,  2000] loss: 0.047\n",
      "[16,  4000] loss: 0.072\n",
      "[16,  6000] loss: 0.078\n",
      "[16,  8000] loss: 0.069\n",
      "[16, 10000] loss: 0.091\n",
      "[16, 12000] loss: 0.068\n",
      "[17,  2000] loss: 0.057\n",
      "[17,  4000] loss: 0.086\n",
      "[17,  6000] loss: 0.059\n",
      "[17,  8000] loss: 0.078\n",
      "[17, 10000] loss: 0.073\n",
      "[17, 12000] loss: 0.090\n",
      "[18,  2000] loss: 0.035\n",
      "[18,  4000] loss: 0.060\n",
      "[18,  6000] loss: 0.072\n",
      "[18,  8000] loss: 0.077\n",
      "[18, 10000] loss: 0.079\n",
      "[18, 12000] loss: 0.096\n",
      "[19,  2000] loss: 0.058\n",
      "[19,  4000] loss: 0.075\n",
      "[19,  6000] loss: 0.047\n",
      "[19,  8000] loss: 0.054\n",
      "[19, 10000] loss: 0.078\n",
      "[19, 12000] loss: 0.083\n",
      "[20,  2000] loss: 0.052\n",
      "[20,  4000] loss: 0.099\n",
      "[20,  6000] loss: 0.088\n",
      "[20,  8000] loss: 0.076\n",
      "[20, 10000] loss: 0.054\n",
      "[20, 12000] loss: 0.085\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "Accuracy for class plane is: 84.3 %\n",
      "Accuracy for class car   is: 89.2 %\n",
      "Accuracy for class bird  is: 80.4 %\n",
      "Accuracy for class cat   is: 74.2 %\n",
      "Accuracy for class deer  is: 85.1 %\n",
      "Accuracy for class dog   is: 67.7 %\n",
      "Accuracy for class frog  is: 83.4 %\n",
      "Accuracy for class horse is: 85.8 %\n",
      "Accuracy for class ship  is: 92.1 %\n",
      "Accuracy for class truck is: 91.2 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), # 256의 크기로 이미지를 늘린다\n",
    "    transforms.CenterCrop(224), # 224만큼 중앙에서부터 자른다(아마 이미지 중에서도 물체가 실제로 존재하는 더 중앙부분을 잘라내는것 같습니다)                            \n",
    "    transforms.ToTensor(), # 데이터셋을 Tensor 정태로 변환(동시에 값이 0 ~ 1로 정규화됨)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet Pytorch 공식 정규화 값이라고 합니다\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# 토치비전을 통해 CIFAR10 데이터셋을 다운로드받고 그것을 trainset에 저장\n",
    "# train 피라미터에 True 값을 넘김으로써 이것은 train 데이터셋이 됨\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# 50000(train dataset size) / 4(batch_size) = 12500번의 iteration을 수행하면 모든 데이터를 다 볼 수 있음\n",
    "# shuffle = True 로 데이터들을 섞음\n",
    "# num_workers는 CPU, GPU의 멀티쓰레딩과 관련된 부분인 것 같은데 자세한 내용은 https://jybaek.tistory.com/799 참고\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# 이번엔 test 데이터셋을 다운받고 변수에 할당\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# testloader는 shuffle = False로 데이터를 섞지 않음 (라벨과 관련이 되어있음)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# class들을 정의\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch hub에서 alexNet을 가져옴\n",
    "# model = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "# 위 코드는 쉽게 모델을 가져올 수 있지만 코랩에서 Http 요청 제한을 넘겨 오류가 발생했음\n",
    "# 그래서 torchvision.models.alexnet 을 사용함\n",
    "model_conv = torchvision.models.alexnet(pretrained=True)\n",
    "\n",
    "# 클래스가 10개이므로 선형 회귀를 통해 10으로 줄어들도록 AlexNet 모델을 변경\n",
    "model_conv.classifier[4] = nn.Linear(4096,1024)\n",
    "model_conv.classifier[6] = nn.Linear(1024,10)\n",
    "                                        \n",
    "# 모델 구조 출력\n",
    "model_conv.eval()\n",
    "\n",
    "# CUDA 사용\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 모델을 CUDA에 맞게 작동하도록 변경\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 크로스 엔트로피 손실 함수 선언\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD 옵티마이저를 사용\n",
    "optimizer = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10): # 에포크 10 설정\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): # 12500번 수행\n",
    "        # inputs와 labels에 data를 나눠서 저장\n",
    "        inputs, labels = data\n",
    "\n",
    "        # inputs 과 labels도 CUDA에 맞게 변환\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # 모든 매개변수의 변화도 버퍼를 0으로 만듦(다음에 나오는 backward와 관련이 있음)\n",
    "        # 0으로 만들지 않으면 backward를 할때마다 변화도가 누적되기 때문\n",
    "\n",
    "        outputs = model_conv(inputs) # inputs 를 model_conv(AlexNet) 신경망에 통과시킴\n",
    "\n",
    "        # 전에 선언했던 크로스 엔트로피 손실 함수를 이용해서 loss 를 평가\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 오차(손실)를 역전파(모델의 매개변수들에 대한 손실의 변화도를 계산)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # 모든 매개변수를 갱신\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # 2000번 마다 알림\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000)) # loss의 평균 출력\n",
    "            running_loss = 0.0\n",
    "            # running_loss 값 초기화\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # 훈련중이 아니므로 no_grad\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_conv(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 여기서도 또한 필요없음\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_conv(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c8c798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.116\n",
      "[1,  4000] loss: 0.135\n",
      "[1,  6000] loss: 0.158\n",
      "[1,  8000] loss: 0.172\n",
      "[1, 10000] loss: 0.151\n",
      "[1, 12000] loss: 0.166\n",
      "[2,  2000] loss: 0.107\n",
      "[2,  4000] loss: 0.130\n",
      "[2,  6000] loss: 0.154\n",
      "[2,  8000] loss: 0.138\n",
      "[2, 10000] loss: 0.135\n",
      "[2, 12000] loss: 0.158\n",
      "[3,  2000] loss: 0.101\n",
      "[3,  4000] loss: 0.131\n",
      "[3,  6000] loss: 0.111\n",
      "[3,  8000] loss: 0.121\n",
      "[3, 10000] loss: 0.126\n",
      "[3, 12000] loss: 0.140\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "Accuracy for class plane is: 88.7 %\n",
      "Accuracy for class car   is: 89.8 %\n",
      "Accuracy for class bird  is: 77.2 %\n",
      "Accuracy for class cat   is: 68.7 %\n",
      "Accuracy for class deer  is: 84.7 %\n",
      "Accuracy for class dog   is: 82.5 %\n",
      "Accuracy for class frog  is: 91.0 %\n",
      "Accuracy for class horse is: 83.8 %\n",
      "Accuracy for class ship  is: 90.1 %\n",
      "Accuracy for class truck is: 92.0 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 에포크를 3 설정\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): # 12500번 수행\n",
    "        # inputs와 labels에 data를 나눠서 저장\n",
    "        inputs, labels = data\n",
    "\n",
    "        # inputs 과 labels도 CUDA에 맞게 변환\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # 모든 매개변수의 변화도 버퍼를 0으로 만듦(다음에 나오는 backward와 관련이 있음)\n",
    "        # 0으로 만들지 않으면 backward를 할때마다 변화도가 누적되기 때문\n",
    "\n",
    "        outputs = model_conv(inputs) # inputs 를 model_conv(AlexNet) 신경망에 통과시킴\n",
    "\n",
    "        # 전에 선언했던 크로스 엔트로피 손실 함수를 이용해서 loss 를 평가\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 오차(손실)를 역전파(모델의 매개변수들에 대한 손실의 변화도를 계산)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step() # 모든 매개변수를 갱신\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # 2000번 마다 알림\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000)) # loss의 평균 출력\n",
    "            running_loss = 0.0\n",
    "            # running_loss 값 초기화\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # 훈련중이 아니므로 no_grad\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_conv(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 여기서도 또한 필요없음\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_conv(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea52383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
